{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "from functools import reduce\n",
    "import utils\n",
    "import os\n",
    "\n",
    "RESULTS_DIR = \"results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from results/dtw_results_for_HMM_1658502416_00.pkl\n",
      "Reading data from results/dtw_results_for_ARIMA_statio_1658516876_00.pkl\n",
      "Reading data from results/hmm_results_for_ARIMA_1658502456_00.pkl\n",
      "Reading data from results/hmm_results_for_HMM_1658502416_00.pkl\n",
      "Reading data from results/dtw_results_for_ARIMA_1658502456_00.pkl\n",
      "Reading data from results/hmm_results_for_ARIMA_statio_1658516876_00.pkl\n"
     ]
    }
   ],
   "source": [
    "results_lst = []\n",
    "for filename in os.listdir(RESULTS_DIR):\n",
    "    path = f\"{RESULTS_DIR}/{filename}\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        print(f\"Reading data from {path}\")\n",
    "        results_lst.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data_filename', 'classificator', 'time_index', 'split_id', 'predictions_dfs', 'accuracies', 'total_time'])\n",
      "dict_keys(['data_filename', 'classificator', 'time_index', 'split_id', 'predictions_dfs', 'accuracies', 'total_time'])\n",
      "dict_keys(['data_filename', 'classificator', 'time_index', 'split_id', 'predictions_dfs', 'accuracies', 'total_time'])\n",
      "dict_keys(['data_filename', 'classificator', 'time_index', 'split_id', 'predictions_dfs', 'accuracies', 'total_time'])\n",
      "dict_keys(['data_filename', 'classificator', 'time_index', 'split_id', 'predictions_dfs', 'accuracies', 'total_time'])\n",
      "dict_keys(['data_filename', 'classificator', 'time_index', 'split_id', 'predictions_dfs', 'accuracies', 'total_time'])\n"
     ]
    }
   ],
   "source": [
    "# Make sure all results are in the same format\n",
    "for r in results_lst:\n",
    "    print(r.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info about generated data in 0:\n",
      "dict_keys(['generating_model', 'data_filename', 'time_index', 'models_lst', 'labels_df', 'all_X_samples', 'all_Z_samples', 'indices_splits_lst', 'metadata'])\n",
      "Info about generated data in 1:\n",
      "dict_keys(['generating_model', 'data_filename', 'time_index', 'models_lst', 'labels_df', 'all_X_samples', 'indices_splits_lst', 'metadata', 'description'])\n",
      "Info about generated data in 2:\n",
      "dict_keys(['generating_model', 'data_filename', 'time_index', 'models_lst', 'labels_df', 'all_X_samples', 'indices_splits_lst', 'metadata'])\n",
      "Info about generated data in 3:\n",
      "dict_keys(['generating_model', 'data_filename', 'time_index', 'models_lst', 'labels_df', 'all_X_samples', 'all_Z_samples', 'indices_splits_lst', 'metadata'])\n",
      "Info about generated data in 4:\n",
      "dict_keys(['generating_model', 'data_filename', 'time_index', 'models_lst', 'labels_df', 'all_X_samples', 'indices_splits_lst', 'metadata'])\n",
      "Info about generated data in 5:\n",
      "dict_keys(['generating_model', 'data_filename', 'time_index', 'models_lst', 'labels_df', 'all_X_samples', 'indices_splits_lst', 'metadata', 'description'])\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(results_lst):\n",
    "    with open(r[\"data_filename\"], \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        print(f\"Info about generated data in {i}:\")\n",
    "        print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare accuracies\n",
    "\n",
    "- `time_id`: time index of file with generated data / results\n",
    "- `gen_with`: type of model the data was generated with (\"HMM\" / \"ARIMA\" / \"ARIMA_all_statio\" etc)\n",
    "- `n_train`: number of train samples per model\n",
    "- `n_test`: number of test samples per model\n",
    "- `min_len`: min sample size parameter used in generation\n",
    "- `max_len`: max sample size parameter used in generation\n",
    "- `cls_with`: type of model used to classify samples (\"HMM\" / \"DTW\")\n",
    "- `variant`: variant of classification, e.g. for HMM: \"AIC\" or \"BIC\", for DTW: \"1NN\" or \"5NN\" derived as a key from `predictions_dfs` list\n",
    "- `acc`: accuracy of predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>gen_with</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_test</th>\n",
       "      <th>min_len</th>\n",
       "      <th>max_len</th>\n",
       "      <th>cls_with</th>\n",
       "      <th>variant</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1658502416</td>\n",
       "      <td>HMM</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>DTW</td>\n",
       "      <td>1NN</td>\n",
       "      <td>0.829630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1658502416</td>\n",
       "      <td>HMM</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>DTW</td>\n",
       "      <td>5NN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1658516876</td>\n",
       "      <td>ARIMA_statio</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>DTW</td>\n",
       "      <td>1NN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1658516876</td>\n",
       "      <td>ARIMA_statio</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>DTW</td>\n",
       "      <td>5NN</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1658502456</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>HMM</td>\n",
       "      <td>AIC</td>\n",
       "      <td>0.670370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1658502456</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>HMM</td>\n",
       "      <td>BIC</td>\n",
       "      <td>0.670370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1658502416</td>\n",
       "      <td>HMM</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>HMM</td>\n",
       "      <td>AIC</td>\n",
       "      <td>0.970370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1658502416</td>\n",
       "      <td>HMM</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>HMM</td>\n",
       "      <td>BIC</td>\n",
       "      <td>0.970370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1658502456</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>DTW</td>\n",
       "      <td>1NN</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1658502456</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>DTW</td>\n",
       "      <td>5NN</td>\n",
       "      <td>0.522222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1658516876</td>\n",
       "      <td>ARIMA_statio</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>HMM</td>\n",
       "      <td>AIC</td>\n",
       "      <td>0.603704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1658516876</td>\n",
       "      <td>ARIMA_statio</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>HMM</td>\n",
       "      <td>BIC</td>\n",
       "      <td>0.603704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_id      gen_with  n_train  n_test  min_len  max_len cls_with  \\\n",
       "0   1658502416           HMM        5      30       20       50      DTW   \n",
       "1   1658502416           HMM        5      30       20       50      DTW   \n",
       "2   1658516876  ARIMA_statio        5      30       20       50      DTW   \n",
       "3   1658516876  ARIMA_statio        5      30       20       50      DTW   \n",
       "4   1658502456         ARIMA        5      30       20       50      HMM   \n",
       "5   1658502456         ARIMA        5      30       20       50      HMM   \n",
       "6   1658502416           HMM        5      30       20       50      HMM   \n",
       "7   1658502416           HMM        5      30       20       50      HMM   \n",
       "8   1658502456         ARIMA        5      30       20       50      DTW   \n",
       "9   1658502456         ARIMA        5      30       20       50      DTW   \n",
       "10  1658516876  ARIMA_statio        5      30       20       50      HMM   \n",
       "11  1658516876  ARIMA_statio        5      30       20       50      HMM   \n",
       "\n",
       "   variant       acc  \n",
       "0      1NN  0.829630  \n",
       "1      5NN  0.733333  \n",
       "2      1NN  0.500000  \n",
       "3      5NN  0.444444  \n",
       "4      AIC  0.670370  \n",
       "5      BIC  0.670370  \n",
       "6      AIC  0.970370  \n",
       "7      BIC  0.970370  \n",
       "8      1NN  0.555556  \n",
       "9      5NN  0.522222  \n",
       "10     AIC  0.603704  \n",
       "11     BIC  0.603704  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_id = []\n",
    "gen_with = []\n",
    "n_train = []\n",
    "n_test = []\n",
    "min_len = []\n",
    "max_len = []\n",
    "cls_with = []\n",
    "variants = []\n",
    "accs = []\n",
    "\n",
    "for r in results_lst:\n",
    "    for variant, acc in r[\"accuracies\"].items():\n",
    "        with open(r[\"data_filename\"], \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            time_id.append(r[\"time_index\"])\n",
    "            gen_with.append(data[\"generating_model\"])\n",
    "            n_train.append(data[\"metadata\"][\"N_TRAIN_SAMPLES_PER_MODEL\"])\n",
    "            n_test.append(data[\"metadata\"][\"N_TEST_SAMPLES_PER_MODEL\"])\n",
    "            min_len.append(data[\"metadata\"][\"MIN_SAMPLE_LEN\"])\n",
    "            max_len.append(data[\"metadata\"][\"MAX_SAMPLE_LEN\"])\n",
    "            cls_with.append(r[\"classificator\"])\n",
    "            variants.append(variant)\n",
    "            accs.append(acc)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"time_id\": time_id,\n",
    "    \"gen_with\": gen_with,\n",
    "    \"n_train\": n_train,\n",
    "    \"n_test\": n_test,\n",
    "    \"min_len\": min_len,\n",
    "    \"max_len\": max_len,\n",
    "    \"cls_with\": cls_with,\n",
    "    \"variant\": variants,\n",
    "    \"acc\": accs\n",
    "})\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "824dc94f4a21fb2b9b063d5374c6a5be71ea0704887dd3ffa4e3d703212d1775"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hmm_dtw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
